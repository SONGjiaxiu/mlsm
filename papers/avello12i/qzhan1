•	Overview: 
The author finds many current papers are blindly optimistic about the employment of social media, such as tweeter, to predict the result of election. After scrutinizing these papers, the author decides to present a balanced survey to us, casting doubt upon the prediction of election using tweeter data, by introducing these papers that have strong impact in this field in the chronological order. Furthermore, the author sheds some light on the future research work.
•	Algorithm: 
Not available
•	Hypothesis: 
Not available
•	Data: 
Not available
•	Experiments: 
Not available
•	Results: 
The 4 points that the author concludes from the previous literature are as following:
1.	Social media, such as tweeter, is biased. Tweeter is not a representative and unbiased sample of the voting population.
2.	Self-selection bias exists because of the minority of users responsible for most of the political chatter.
3.	A substantial amount of data on tweeter is untrustworthy.
4.	Due to the nature of political discourse, which is plagued with humor, double entendres and sarcasm, simplistic sentiment analysis methods perform very badly.
The author suggests that anyone who has ambition to conduct serious research on prediction of election using tweeter data should keep above 4 points in mind.
•	Assumptions:
Not available
•	Synthesis: 
First of all, I agree with the author that the tweeter is incapable of being a representative and unbiased sample of the voting population. Actually, the folks who use tweeter for political chatter might be just a little fraction of the whole voting population. To address this issue, I suggest that the impact factor of tweeter user might be introduced into the research. Consider the fact some guys who are enthusiastic about tweeting for political chatter might be invisible by the most voting population. On the other hand, some tweeters, such as some celebrities or journalists, might have huge influence on voting population. These two kinds of tweeters should not weigh the same. Meanwhile, I believe the impact factor can help reduce the self-selection bias. Regarding point 3, “a substantial amount of data on tweeter is untrustworthy”, the author already sheds light upon it. We should discriminate different tweeter data. The algorithm is supposed to be designed to distinguish the credible tweeters from the incredible tweeters, probably by scoring the credibility of every tweeter user. Finally, when it comes to the bad performance of simplistic sentiment classification, I believe the classification can be more precise with the development of research on natural language process. 
 
•	Related Papers: 

1.	Holt, Kristoffer.; Shehata, Adam.; Stromback, Jesper.; Ljungberg, Elisabet. 2013. Age and the effects of news media attention and social media use on political interest and participation: Do social media function as leveller? In European Journal of Communication Feb2013, Vol. 28 Issue 1, p19-34-34

This article investigates how media use differs across age groups- and whether this matters for people's inclination to participate politically. I believe this article provides some evidence to explain the feasibility of predicting election using social media data.

2.	Towner, Terri L. 2013. All Political Participation Is Socially Networked?: New Media and the 2012 Election. In Social Science Computer Review Oct2013, Vol. 31 Issue 5, p527-541

This research examined the influence of attention to specific forms of traditional and online media on young adults' online and offline political participation as well as voter turnout during the fall 2012 presidential campaign. This article might give us some ideas that how the attention shifts between online media and traditional media. Thus, the time factor probably should be taken into count too, when we design the algorithm to predict the result of election.
