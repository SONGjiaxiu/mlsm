{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# In this example, I walk through how to use sklearn to classify users into male or female\n",
      "# based on their user description.\n",
      "\n",
      "# First, we need to get some tweets in JSON format.\n",
      "# Create a tweets.json file with something like:\n",
      "# twitter-curl --query \"track=obama\" > tweets.json\n",
      "# This will query twitter for tweets containing the word obama.\n",
      "\n",
      "# Now, we'll parse that file into a list of (name, description) tuples.\n",
      "import json\n",
      "import io\n",
      "# open the json file\n",
      "fp = io.open('tweets.json', mode='rt', encoding='utf8')\n",
      "# read the names and description fields from each tweet.\n",
      "data = []\n",
      "for line in fp:\n",
      "    js = json.loads(line)  # parse into a JSON object.\n",
      "    name = js['user']['name']\n",
      "    description = js['user']['description']\n",
      "    if name and description:  # if fields aren't blank\n",
      "        data.append((name.lower(), description.lower()))\n",
      "print 'read', len(data), 'users'\n",
      "print 'example:', data[0]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "read 7525 users\n",
        "example: (u'conservative chick', u\"i'm that evil conservative obama warned you about...               pro-palin #conservative, #pro-life,\")\n"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now, we need to label them as male or female. \n",
      "# To do that, we get the top 500 male/female names from census\n",
      "import requests  # This is a very handy library for html requests.\n",
      "males = requests.get('http://www.census.gov/genealogy/www/data/1990surnames/dist.male.first').text.split('\\n')\n",
      "males = [m.split()[0].lower() for m in males[:500]]  # lower case and take top 500\n",
      "print 'first male is', males[0]\n",
      "females = requests.get('http://www.census.gov/genealogy/www/data/1990surnames/dist.female.first').text.split('\\n')\n",
      "females = [f.split()[0].lower() for f in females[:500]]  # lower case and take top 500\n",
      "print 'first female is', females[0]\n",
      "\n",
      "# Remove ambiguous names (those that appear on both lists)\n",
      "# Note that the plus operator is overloaded to mean concatentation for lists.\n",
      "ambiguous = [f for f in females + males if f in males and f in females]\n",
      "print 'ambiguous is', ambiguous[0]\n",
      "males = [m for m in males if m not in ambiguous]\n",
      "females = [f for f in females if f not in ambiguous]\n",
      "print 'got', len(males), 'males and', len(females), 'females'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "first male is james\n",
        "first female is"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " mary\n",
        "ambiguous is jean\n",
        "got 473 males and 473 females\n"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sort male, female users\n",
      "male_users = [d for d in data if len(d[0].split()) > 0 and d[0].split()[0] in males]\n",
      "print len(male_users), 'males'\n",
      "print male_users[0]\n",
      "female_users = [d for d in data if len(d[0].split()) > 0 and d[0].split()[0] in females]\n",
      "print len(female_users), 'females'\n",
      "print female_users[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "499 males\n",
        "(u'daniel john sobieski', u\"editorial writer, investor's business daily, #reagan #conservative, somewhere to the right of attila the hun #catholic #prolife #tcot #teaparty #nra\")\n",
        "242 females\n",
        "(u'jessica cranor ', u'lame, nerdy, brilliant, fantastic')\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Make target vector. Female=1, Male=0\n",
      "import numpy as np\n",
      "y = np.array([0.] * len(male_users) + [1.] * len(female_users))\n",
      "data = [d[1] for d in male_users + female_users]\n",
      "print 'first label=', y[0]\n",
      "print 'first description=', data[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "first label= 0.0\n",
        "first description= editorial writer, investor's business daily, #reagan #conservative, somewhere to the right of attila the hun #catholic #prolife #tcot #teaparty #nra\n"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Convert descriptions into feature vectors.\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "vec = CountVectorizer()\n",
      "X = vec.fit_transform(data)\n",
      "print data[0],'\\nis transformed into the sparse vector\\n', X[0]\n",
      "print 'the word THE is mapped to index', vec.vocabulary_['the']\n",
      "print 'there are', len(vec.vocabulary_), 'unique features'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "editorial writer, investor's business daily, #reagan #conservative, somewhere to the right of attila the hun #catholic #prolife #tcot #teaparty #nra \n",
        "is transformed into the sparse vector\n",
        "  (0, 284)\t1\n",
        "  (0, 492)\t1\n",
        "  (0, 542)\t1\n",
        "  (0, 700)\t1\n",
        "  (0, 787)\t1\n",
        "  (0, 980)\t1\n",
        "  (0, 1529)\t1\n",
        "  (0, 1626)\t1\n",
        "  (0, 2180)\t1\n",
        "  (0, 2213)\t1\n",
        "  (0, 2479)\t1\n",
        "  (0, 2562)\t1\n",
        "  (0, 2650)\t1\n",
        "  (0, 2882)\t1\n",
        "  (0, 3027)\t1\n",
        "  (0, 3036)\t1\n",
        "  (0, 3067)\t2\n",
        "  (0, 3113)\t1\n",
        "  (0, 3430)\t1\n",
        "the word THE is mapped to index 3067\n",
        "there are 3488 unique words\n"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compute cross validation accuracy\n",
      "from sklearn import cross_validation\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "clf = LogisticRegression()\n",
      "print 'avg accuracy=%.3f' % np.average(cross_validation.cross_val_score(clf, X, y, cv=5, scoring='accuracy'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "avg accuracy=0.749\n"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Try Naive Bayes\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "clf = MultinomialNB()\n",
      "print 'avg accuracy=%.3f' % np.average(cross_validation.cross_val_score(clf, X, y, cv=5, scoring='accuracy'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "avg accuracy=0.671\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Try adding bigrams\n",
      "vec = CountVectorizer(ngram_range=(1,2))\n",
      "X = vec.fit_transform(data)\n",
      "print 'there are', len(vec.vocabulary_), 'unique features'\n",
      "print 'ten feature examples:', vec.vocabulary_.keys()[:10]\n",
      "from sklearn import cross_validation\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "clf = LogisticRegression()\n",
      "print 'avg accuracy with bigrams=%.3f' % np.average(cross_validation.cross_val_score(clf, X, y, cv=5, scoring='accuracy'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "there are 10570 unique features\n",
        "ten feature examples: [u'loving faithful', u'web manager', u'your password', u'yellow', u'four', u'fight against', u'politically conservatarian', u'looking', u'america stop', u'wake up']\n",
        "avg accuracy with bigrams=0.749\n"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Print top feature weights for female\n",
      "clf = LogisticRegression()\n",
      "clf.fit(X, y)  # fit on all data\n",
      "top_indices = clf.coef_[0].argsort()[::-1] # sort in decreasing order\n",
      "# reverse the alphabet to map from idx->word\n",
      "vocab_r = dict((idx, word) for word, idx in vec.vocabulary_.iteritems())\n",
      "print 'female words\\n:', '\\n'.join(['%s=%.3f' % (vocab_r[idx], clf.coef_[0][idx]) for idx in top_indices[:10]])\n",
      "top_indices = clf.coef_[0].argsort() # sort in increasing order\n",
      "print '\\n\\nmale words:\\n', '\\n'.join(['%s=%.3f' % (vocab_r[idx], clf.coef_[0][idx]) for idx in top_indices[:10]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "female words\n",
        ": christian=1.392\n",
        "life=1.010\n",
        "mom=0.830\n",
        "is=0.771\n",
        "wife=0.754\n",
        "mother=0.704\n",
        "grandmother=0.655\n",
        "sup=0.639\n",
        "politics=0.634\n",
        "follow=0.563\n",
        "\n",
        "\n",
        "male words:\n",
        "veteran=-0.893\n",
        "sports=-0.873\n",
        "father=-0.798\n",
        "husband=-0.728\n",
        "writer=-0.635\n",
        "of the=-0.603\n",
        "conservative christian=-0.602\n",
        "make=-0.592\n",
        "political=-0.554\n",
        "your=-0.547\n"
       ]
      }
     ],
     "prompt_number": 123
    }
   ],
   "metadata": {}
  }
 ]
}